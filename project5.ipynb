{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SAVE_PATH = './regensburg_pediatric_appendicitis.csv'  \n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(SAVE_PATH)\n",
    "except:\n",
    "    from ucimlrepo import fetch_ucirepo \n",
    "    regensburg_pediatric_appendicitis = fetch_ucirepo(id=938) \n",
    "    data_a = regensburg_pediatric_appendicitis['data']['features']\n",
    "    data_b = regensburg_pediatric_appendicitis['data']['targets']\n",
    "    data = pd.concat([data_a, data_b ], axis=1)\n",
    "    data.to_csv(SAVE_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# remove targets column\n",
    "categorical_cols = categorical_cols.drop('Diagnosis')\n",
    "categorical_cols = categorical_cols.drop('Management')\n",
    "categorical_cols = categorical_cols.drop('Severity')\n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "#convert true false to 1 0\n",
    "data_encoded = data_encoded.replace({True: 1, False: 0})\n",
    "\n",
    "display(data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = data_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "display(numerical_features)\n",
    "\n",
    "# sns.kdeplot(data=data_encoded[numerical_features], label = numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not normally distributed -- Use Mann-Whitney U test\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "appendicitis = data_encoded[data_encoded['Diagnosis'] == 'appendicitis']\n",
    "no_appendicitis = data_encoded[data_encoded['Diagnosis'] == 'no appendicitis']\n",
    "len(appendicitis), len(no_appendicitis)\n",
    "\n",
    "appendicitis = appendicitis[numerical_features]\n",
    "no_appendicitis = no_appendicitis[numerical_features]\n",
    "\n",
    "\n",
    "results = []\n",
    "for feat in numerical_features:\n",
    "    #temperarily drop NA values\n",
    "    appendicitis = appendicitis.dropna(subset=[feat])\n",
    "    no_appendicitis = no_appendicitis.dropna(subset=[feat])\n",
    "    if len(appendicitis) == 0 or len(no_appendicitis) == 0:\n",
    "        continue\n",
    "    t_test = mannwhitneyu(appendicitis[feat], no_appendicitis[feat], alternative=\"two-sided\")\n",
    "    results.append([feat, t_test.statistic, t_test.pvalue])\n",
    "\n",
    "num_feat_diagnosis = pd.DataFrame(results, columns=[\"feature\", \"statistic\", \"pvalue\"])\n",
    "\n",
    "sorted_num_feat_diagnosis = num_feat_diagnosis.sort_values(by=\"statistic\", ascending=False)\n",
    "\n",
    "display(sorted_num_feat_diagnosis)\n",
    "\n",
    "#bonfroni correction\n",
    "signifigance = 0.05 / len(numerical_features)\n",
    "display(signifigance)\n",
    "\n",
    "num_feat_diagnosis = sorted_num_feat_diagnosis[sorted_num_feat_diagnosis['pvalue'] < signifigance]\n",
    "num_feat_diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_encoded.columns:\n",
    "    if 'Management' in col:\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing but now predicting the other targets\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "#management\n",
    "conservative = data_encoded[data_encoded['Management'] == \"conservative\"]\n",
    "primary_surgical = data_encoded[data_encoded['Management'] == \"primary surgical\"]\n",
    "secondary_surgical = data_encoded[data_encoded['Management'] == \"secondary surgical\"]\n",
    "simultaneous_appendectomy = data_encoded[data_encoded['Management'] == \"simultaneous appendectomy\"]\n",
    "len(conservative), len(primary_surgical), len(secondary_surgical), len(simultaneous_appendectomy)\n",
    "\n",
    "conservative = conservative[numerical_features]\n",
    "primary_surgical = primary_surgical[numerical_features]\n",
    "secondary_surgical = secondary_surgical[numerical_features]\n",
    "simultaneous_appendectomy = simultaneous_appendectomy[numerical_features]\n",
    "len(conservative), len(primary_surgical), len(secondary_surgical), len(simultaneous_appendectomy)\n",
    "#we won't use simultaneous appendectomy because there's only 1 value\n",
    "\n",
    "results = []\n",
    "for feat in numerical_features:\n",
    "    #temperarily drop NA values\n",
    "    conservative = conservative.dropna(subset=[feat])\n",
    "    primary_surgical = primary_surgical.dropna(subset=[feat])\n",
    "    secondary_surgical = secondary_surgical.dropna(subset=[feat])\n",
    "    if len(conservative) == 0 or len(primary_surgical) == 0 or len(secondary_surgical) == 0:\n",
    "        continue\n",
    "    t_test = kruskal(conservative[feat], primary_surgical[feat], secondary_surgical[feat])\n",
    "    results.append([feat, t_test.statistic, t_test.pvalue])\n",
    "\n",
    "num_feat_management = pd.DataFrame(results, columns=[\"feature\", \"statistic\", \"pvalue\"])\n",
    "display(num_feat_management)\n",
    "\n",
    "#bonfroni correction\n",
    "signifigance = 0.05 / len(numerical_features)\n",
    "display(signifigance)\n",
    "\n",
    "num_feat_management = num_feat_management[num_feat_management['pvalue'] < signifigance]\n",
    "num_feat_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#severity\n",
    "unique_severity = data_encoded['Severity'].unique()\n",
    "print(unique_severity)\n",
    "\n",
    "complicated = data_encoded[data_encoded['Severity'] == \"complicated\"]\n",
    "uncomplicated = data_encoded[data_encoded['Severity'] == \"uncomplicated\"]\n",
    "display(len(complicated), len(uncomplicated))\n",
    "\n",
    "complicated = complicated[numerical_features]\n",
    "uncomplicated = uncomplicated[numerical_features]\n",
    "\n",
    "\n",
    "results = []\n",
    "for feat in numerical_features:\n",
    "    #temperarily drop NA values\n",
    "    complicated = complicated.dropna(subset=[feat])\n",
    "    uncomplicated = uncomplicated.dropna(subset=[feat])\n",
    "    if len(complicated) == 0 or len(uncomplicated) == 0:\n",
    "        continue\n",
    "    t_test = mannwhitneyu(complicated[feat], uncomplicated[feat], alternative=\"two-sided\")\n",
    "    results.append([feat, t_test.statistic, t_test.pvalue])\n",
    "\n",
    "num_feat_severity = pd.DataFrame(results, columns=[\"feature\", \"statistic\", \"pvalue\"])\n",
    "display(num_feat_severity)\n",
    "\n",
    "#bonfroni correction\n",
    "signifigance = 0.05 / len(numerical_features)\n",
    "display(signifigance)\n",
    "\n",
    "num_feat_severity = num_feat_severity[num_feat_severity['pvalue'] < signifigance]\n",
    "num_feat_severity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for categotrical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# COL = 'Diagnosis_no appendicitis'\n",
    "\n",
    "# # Calculate Pearson correlation coefficients and p-values\n",
    "# correlation_results = []\n",
    "# for feature in numerical_features:\n",
    "#     corr, p_value = pearsonr(data_encoded[feature], data_encoded[COL])\n",
    "#     correlation_results.append((feature, corr, p_value))\n",
    "\n",
    "# # Convert results to DataFrame\n",
    "# correlation_df = pd.DataFrame(correlation_results, columns=['feature', 'correlation', 'pvalue'])\n",
    "\n",
    "# # Sort by absolute correlation value\n",
    "# correlation_df['abs_correlation'] = correlation_df['correlation'].abs()\n",
    "# correlation_df = correlation_df.sort_values(by='abs_correlation', ascending=False)\n",
    "\n",
    "# # filter out high p-values\n",
    "# correlation_df = correlation_df[correlation_df['pvalue'] < 0.05/len(numerical_features)]\n",
    "\n",
    "# # Drop the Diagnoses column\n",
    "# correlation_df = correlation_df[correlation_df['feature'] != COL]\n",
    "\n",
    "\n",
    "# # Print the sorted features, correlations, and p-values\n",
    "# for i,row in enumerate(correlation_df.itertuples()):\n",
    "#     print(f'{i}: {row.feature}: {row.correlation:.4f} (p-value: {row.pvalue:.4f})')\n",
    "\n",
    "# # select the top 5 features\n",
    "\n",
    "# top_features = correlation_df['feature'].values[:10]\n",
    "# top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "def GaussianNB_train(features_to_use,y_col):\n",
    "\n",
    "    data_encoded_no_na = data_encoded.dropna(subset=features_to_use)\n",
    "    X = data_encoded_no_na[features_to_use]\n",
    "    y = data_encoded_no_na[y_col]\n",
    "\n",
    "    display(X.head(1))\n",
    "\n",
    "    mean_report = {\n",
    "        'accuracy': 0,\n",
    "        'precision': 0,\n",
    "        'recall': 0,\n",
    "        'f1-score': 0\n",
    "    }\n",
    "\n",
    "    TESTS=1000\n",
    "\n",
    "    for i in range(TESTS):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        gnb = GaussianNB()\n",
    "\n",
    "        gnb.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = gnb.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        mean_report['accuracy'] += accuracy\n",
    "        mean_report['precision'] += report['weighted avg']['precision']\n",
    "        mean_report['recall'] += report['weighted avg']['recall']\n",
    "        mean_report['f1-score'] += report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "    for key in mean_report:\n",
    "        mean_report[key] /= TESTS\n",
    "\n",
    "    print(mean_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNB_train(num_feat_diagnosis['feature'], 'Diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNB_train(num_feat_severity['feature'], 'Severity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNB_train(num_feat_management['feature'], 'Management')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ytapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
